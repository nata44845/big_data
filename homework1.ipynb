{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008d8d43",
   "metadata": {},
   "source": [
    "# Домашняя работа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f016163",
   "metadata": {},
   "source": [
    "Сделайте mapper и reducer, чтобы посчитать среднее и дисперсию оценок за фильм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bc15a",
   "metadata": {},
   "source": [
    "Реализация через цикл (предпогаем, что мы не знаем сколько у нас фильмов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92212584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in e:\\nata\\python\\anaconda3\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: click in e:\\nata\\python\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: kaggle in e:\\nata\\python\\anaconda3\\lib\\site-packages (from opendatasets) (1.5.16)\n",
      "Requirement already satisfied: tqdm in e:\\nata\\python\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.0)\n",
      "Requirement already satisfied: colorama in e:\\nata\\python\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.4)\n",
      "Requirement already satisfied: python-slugify in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: certifi in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.27.1)\n",
      "Requirement already satisfied: six>=1.10 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.9)\n",
      "Requirement already satisfied: bleach in e:\\nata\\python\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (4.1.0)\n",
      "Requirement already satisfied: webencodings in e:\\nata\\python\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: packaging in e:\\nata\\python\\anaconda3\\lib\\site-packages (from bleach->kaggle->opendatasets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from packaging->bleach->kaggle->opendatasets) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\nata\\python\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b854658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624d10db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\imdb-user-reviews\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('imdb-user-reviews', 'song_lyrics.csv')\n",
    "if not dataset_path.is_file():\n",
    "    od.download('https://www.kaggle.com/datasets/sadmadlad/imdb-user-reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999fcf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "n, mean, M2 = 0, 0.0, 0\n",
    "for path in Path('imdb-user-reviews').glob('**/*'):\n",
    "    if path.is_file() and path.suffix == '.json':\n",
    "        with open(path, 'r') as f:\n",
    "            info = json.load(f)\n",
    "        score = float(info['movieIMDbRating'])\n",
    "        n += 1\n",
    "        delta = score - mean\n",
    "        mean += delta / n\n",
    "        M2 += delta * (score - mean)\n",
    "\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c152e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(path):\n",
    "    score = 0\n",
    "    if path.is_file() and path.suffix == '.json':\n",
    "        with open(path, 'r') as f:\n",
    "            info = json.load(f)\n",
    "        return(1,float(info['movieIMDbRating']),None)\n",
    "    return None\n",
    "\n",
    "\n",
    "def reducer(score1, score2):\n",
    "    if score1 is None and score2 is None:\n",
    "        return None\n",
    "    elif score1 is None:\n",
    "        return score2\n",
    "    elif score2 is None:\n",
    "        return score1\n",
    "    else:\n",
    "        scores = []\n",
    "        if score1[2] == None:\n",
    "            n, mean, M2 = 0, 0.0, 0\n",
    "            scores.append(score1[1])\n",
    "        else:\n",
    "            n, mean, M2 = score1\n",
    "        scores.append(score2[1])\n",
    "        \n",
    "        for score in scores:\n",
    "            n += 1\n",
    "            delta = score - mean\n",
    "            mean += delta / n\n",
    "            M2 += delta * (score - mean)\n",
    "        return n, mean, M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74460f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None None None None None None None None (1, 8.4, None) None (1, 8.8, None) None (1, 7.4, None) None (1, 8.4, None) None (1, 5.2, None) None (1, 8.9, None) None (1, 8.3, None) None (1, 8.0, None) None (1, 9.0, None) None (1, 7.9, None) None\n"
     ]
    }
   ],
   "source": [
    "print(*map(mapper, Path('imdb-user-reviews').glob('**/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3e17ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 8.03 1.0517128885774865\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(reducer, map(mapper, Path('imdb-user-reviews').glob('**/*')))\n",
    "print(n, mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cb533",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd97685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff89dbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 936 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 2\n",
    "n, mean, M2 = reduce(reducer, Parallel(n_jobs=N)(delayed(mapper)(path) for path in Path('imdb-user-reviews').glob('**/*')))\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6d9d1ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 8\n",
    "n, mean, M2 = reduce(reducer, Parallel(n_jobs=N)(delayed(mapper)(path) for path in Path('imdb-user-reviews').glob('**/*')))\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d4b383b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 16\n",
    "n, mean, M2 = reduce(reducer, Parallel(n_jobs=N)(delayed(mapper)(path) for path in Path('imdb-user-reviews').glob('**/*')))\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21ccc2",
   "metadata": {},
   "source": [
    "# Chunkify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a39d88b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c9bf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee      \n",
    "def split_gen(gen):\n",
    "    gen_a, gen_b = tee(gen, 2)\n",
    "    return (a for a, b in gen_a), (b for a, b in gen_b)\n",
    "\n",
    "\n",
    "def chunkify(list_of_strings, number_of_chunks=30):\n",
    "    step = len(list_of_strings) // number_of_chunks\n",
    "    if step != 0:\n",
    "        for i in range(0, len(list_of_strings), step):\n",
    "            yield list_of_strings[i : i + step]\n",
    "    else:\n",
    "        yield list_of_strings  # Генераторы\n",
    "        \n",
    "\n",
    "def chunks_mapper(chunk):\n",
    "    mapped_chunk = map(mapper, chunk)\n",
    "    mapped_chunk = zip(chunk, mapped_chunk)\n",
    "    return reduce(reducer, mapped_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1f7f5179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<generator object split_gen.<locals>.<genexpr> at 0x000001F69F3E96D0>, <generator object split_gen.<locals>.<genexpr> at 0x000001F69F3E9270>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable WindowsPath object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:7\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [191]\u001b[0m, in \u001b[0;36mchunks_mapper\u001b[1;34m(chunk)\u001b[0m\n\u001b[0;32m     17\u001b[0m mapped_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(mapper, chunk)\n\u001b[0;32m     18\u001b[0m mapped_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(chunk, mapped_chunk)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_chunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [191]\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_gen\u001b[39m(gen):\n\u001b[0;32m      3\u001b[0m     gen_a, gen_b \u001b[38;5;241m=\u001b[39m tee(gen, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m gen_a), (b \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m gen_b)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable WindowsPath object"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_chunks = split_gen(Path('imdb-user-reviews').glob('**/*'))\n",
    "for i in data_chunks:\n",
    "    print(*i)\n",
    "#step 1:\n",
    "mapped = map(chunks_mapper, data_chunks)\n",
    "\n",
    "#step 2:\n",
    "reduced = reduce(reducer, mapped)\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19b741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb111e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
